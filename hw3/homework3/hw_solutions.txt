I=10000000

6.    uint32 arrays (4 bytes)
    Inital Time: 1.620096 s
    Vectorized Time: 0.386919 s         vectorization width: 4 
    AVX2 Time: 0.286102 s               vectorization width: 8

    Unvectorized -> vectorized: 4.187x speed up
    default -> AVX2: 1.352x speed up

    AVX2 vector register bit width is twice as long
    SSE: vectorization width * width of uint32 = 4 * 4 = 16 byte registers
    AVX2: vectorization width * width of uint32 = 8 * 4 = 32 byte registers

7.
    Vector add operation in SSE: paddd (packed add of doubles(4 bytes))
    Vector add operation in AVX2: vpaddd (vector packed add of doubles(4 bytes))

8.
    The SSE version does this complex series of shuffles and multiplies to come out to the shifted outcome. While the AVX2 version just does a straight forward approach of loading
    in the data and then shifting it by the amount B specifies and saving it into C. This happens because shifting by a variable amount is only supported in AVX2, so the SSE version
    has to do various tricks to mimic this behavior.

9.
    uint64:
    Inital Time: 1.673424 s
    Vectorized Time: 0.718811 s         vectorization width: 2
    AVX2 Time: 0.564536 s               vectorization width: 4

    uint16:
    Inital Time: 1.625603 s
    Vectorized Time: 0.186579 s         vectorization width: 8
    AVX2 Time: 0.002011 s               vectorization width: 16

    uint8:
    Inital Time: 1.693556 s
    Vectorized Time: 0.101193 s         vectorization width: 16
    AVX2 Time: 0.002062 s               vectorization width: 32

10.
    uint64 and *
        Initial Time: 2.048793
        AVX2 Time: 1.540229
    uint8 and *
        Initial Time: 2.127674
        AVX2 Time: 0.217731

11.
    The multiply operations for the large data types took a series of multiplies, adds, and other operations to come to the correct result which caused the multiply to take 
    much longer than the simple add. This happens because the machine doesn't support straight up multiplying to 64 bit integer and so has to do it in a series of steps.
    The difference between multiply and add because less prevalent at lower data type widths where the assembly can just do a single multiply instruction.

12. 
    N = 999  uint32 and +
    Inital Time: 1.600762 s
    Vectorized Time: 0.448929 s         vectorization width: 4 
    AVX2 Time: 0.348086 s               vectorization width: 8

    N = 1027  uint32 and +
    Inital Time: 1.723454 s
    Vectorized Time: 0.454269 s         vectorization width: 4 
    AVX2 Time: 0.283879 s               vectorization width: 8

    While noticable, the performance difference is not very substantial. This is because for the majority of the array it will still be done in a vectorized fashion as usual.
    It is only the last section of the array which is not big enough to fit in a vector register that is done with a normal loop.
